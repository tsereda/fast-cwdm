apiVersion: batch/v1
kind: Job
metadata:
  name: fast-cwdm-job-fixed
  labels:
    app: fast-cwdm
spec:
  backoffLimit: 0
  template:
    metadata:
      labels:
        app: fast-cwdm
    spec:
      nodeSelector:
        topology.kubernetes.io/region: us-west
        nautilus.io/linstor: "true"
      containers:
        - name: brats-processing
          image: gitlab-registry.nrp-nautilus.io/prp/jupyter-stack/prp
          env:
            - name: REPO_PATH
              value: /app/fast-cwdm
            - name: PYTHONPATH
              value: /app/fast-cwdm
            - name: CUDA_VISIBLE_DEVICES
              value: "0"
            - name: nnUNet_raw
              value: /app/nnunet/raw
            - name: nnUNet_preprocessed
              value: /app/nnunet/preprocessed
            - name: nnUNet_results
              value: /app/nnunet/results
            - name: PYTHONUNBUFFERED
              value: "1"
            - name: PYTHONIOENCODING
              value: "UTF-8"
            - name: WANDB_API_KEY
              valueFrom:
                secretKeyRef:
                  name: wandb-credentials
                  key: api-key
            - name: WANDB_PROJECT
              value: "cwmd-3d-brats"
            - name: WANDB_ENTITY
              value: "timgsereda"
            - name: WANDB_MODE
              value: "online"
            - name: USE_TENSORBOARD
              value: "true"
          command: ["/bin/bash", "-c"]
          args:
            - |
              # Add GPU debugging at the start
              echo "=== GPU DEBUG INFO ==="
              nvidia-smi || echo "nvidia-smi not available"
              echo "CUDA_VISIBLE_DEVICES: $CUDA_VISIBLE_DEVICES"
              echo "User: $(whoami)"
              echo "Python location: $(which python)"
              echo ""
              
              git clone https://github.com/tsereda/fast-cwdm.git ${REPO_PATH}
              cd ${REPO_PATH}
              
              sudo apt-get update && sudo apt-get install -y p7zip-full wget git
              
              # Create dataset directories
              mkdir -p datasets/BRATS2023/training
              mkdir -p datasets/BRATS2023/validation
              
              # Copy ZIP files to local workspace and extract directly to target directories
              for dataset in "TrainingData" "ValidationData"; do
                zip_file="/data/ASNR-MICCAI-BraTS2023-GLI-Challenge-${dataset}.zip"
                local_zip="/app/ASNR-MICCAI-BraTS2023-GLI-Challenge-${dataset}.zip"
                
                if [ -f "$zip_file" ]; then
                  echo "Copying ${dataset} ZIP to local workspace..."
                  cp "$zip_file" "$local_zip"
                  
                  echo "Extracting ${dataset}..."
                  # Extract to temp directory
                  mkdir -p /tmp/extract
                  7z x "$local_zip" -o"/tmp/extract" -y
                  
                  # Move contents to final destination
                  if [ "$dataset" = "TrainingData" ]; then
                    mv /tmp/extract/ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData/* datasets/BRATS2023/training/
                  elif [ "$dataset" = "ValidationData" ]; then
                    mv /tmp/extract/ASNR-MICCAI-BraTS2023-GLI-Challenge-ValidationData/* datasets/BRATS2023/validation/
                  fi
                  
                  # Clean up
                  rm -rf /tmp/extract
                  rm "$local_zip"
                  
                  echo "${dataset} processed successfully"
                fi
              done
              
              echo "Training patients: $(ls datasets/BRATS2023/training/ | wc -l)"
              echo "Validation patients: $(ls datasets/BRATS2023/validation/ | wc -l)"
              echo "Sample training patient files: $(ls datasets/BRATS2023/training/BraTS-GLI-00000-000/ | wc -l)"
              
              # STEP 1: Install dependencies with CUDA-enabled PyTorch using pip (like the working job)
              echo "=== Installing PyTorch with CUDA support ==="
              pip install --upgrade pip
              pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117
              pip install pyyaml tqdm numpy nibabel wandb matplotlib blobfile tensorboard
              
              # STEP 2: Test CUDA availability BEFORE conda environment
              echo "=== Testing CUDA availability (pip install) ==="
              python -c "
              import torch
              print(f'PyTorch version (pip): {torch.__version__}')
              print(f'CUDA available (pip): {torch.cuda.is_available()}')
              print(f'CUDA version (pip): {torch.version.cuda}')
              print(f'GPUs available (pip): {torch.cuda.device_count()}')
              if torch.cuda.is_available():
                  for i in range(torch.cuda.device_count()):
                      print(f'GPU {i}: {torch.cuda.get_device_name(i)}')
              else:
                  print('WARNING: CUDA not available with pip install')
              "
              
              # STEP 3: Setup conda environment but override PyTorch
              echo "=== Setting up conda environment ==="
              conda init bash
              source ~/.bashrc
              
              # Check what's in environment.yml first
              echo "=== Checking environment.yml contents ==="
              cat environment.yml | grep -i pytorch || echo "No pytorch found in environment.yml"
              cat environment.yml | grep -i torch || echo "No torch found in environment.yml"
              
              # Create the environment
              mamba env create -f environment.yml
              
              # Activate and override PyTorch with CUDA version
              eval "$(conda shell.bash hook)"
              conda activate cwdm
              
              echo "=== Conda environment activated ==="
              conda info --envs
              python --version
              which python
              
              # CRITICAL: Override any CPU-only PyTorch from environment.yml
              echo "=== Overriding PyTorch with CUDA version in conda environment ==="
              pip install --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117
              
              # STEP 4: Final CUDA verification in conda environment
              echo "=== Final CUDA verification (conda environment) ==="
              python -c "
              import torch
              print(f'PyTorch version (conda final): {torch.__version__}')
              print(f'CUDA available (conda final): {torch.cuda.is_available()}')
              print(f'CUDA version (conda final): {torch.version.cuda}')
              print(f'GPUs available (conda final): {torch.cuda.device_count()}')
              if torch.cuda.is_available():
                  for i in range(torch.cuda.device_count()):
                      print(f'GPU {i}: {torch.cuda.get_device_name(i)}')
                      print(f'GPU {i} memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB')
              else:
                  print('ERROR: CUDA still not available after fixes!')
                  exit(1)
              "
              
              python -c "import wandb; print(f'W&B version: {wandb.__version__}')"

              LOGDIR="/data/runs"

              echo "Training patients: $(ls datasets/BRATS2023/training/ | wc -l)"
              echo "Validation patients: $(ls datasets/BRATS2023/validation/ | wc -l)"
              echo "Sample training patient files: $(ls datasets/BRATS2023/training/BraTS-GLI-00000-000/ | wc -l)"

              # Final verification before starting training
              echo "=== Starting training with CUDA verification ==="
              python -c "
              import torch
              assert torch.cuda.is_available(), 'CUDA must be available for training'
              assert torch.cuda.device_count() > 0, 'At least one GPU must be available'
              print('âœ“ CUDA verification passed, starting training...')
              "

              bash run.sh --sampling-strategy direct --timesteps 1000 --mode train --train_modality all
              
              ls -la /data/checkpoints/

              echo "Job completed successfully"
         
          volumeMounts:
            - name: workspace
              mountPath: /app
            - name: data
              mountPath: /data
            - name: shm
              mountPath: /dev/shm
          resources:
            requests:
              memory: 25Gi
              cpu: "15"
              nvidia.com/a100: "1"
            limits:
              memory: 30Gi
              cpu: "18"
              nvidia.com/a100: "1"
      volumes:
        - name: workspace
          emptyDir:
            sizeLimit: 50Gi
        - name: data
          persistentVolumeClaim:
            claimName: brats2025-3
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi
      restartPolicy: Never